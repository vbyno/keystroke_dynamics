{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tabulate\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "DataTransformerRegistry.enable('default')"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.data_transformers.enable('default', max_rows=None) \n",
    "# alt.renderers.enable('default')\n",
    "# alt.renderers.enable('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "DataTransformerRegistry.enable('custom')"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save temp altair json files in separate folder\n",
    "os.makedirs('tmp/altdata', exist_ok=True)\n",
    "\n",
    "def custom(data):\n",
    "    return alt.pipe(data, alt.to_json(filename='tmp/altdata/{prefix}-{hash}.{extension}') )\n",
    "\n",
    "alt.data_transformers.register('custom', custom)\n",
    "alt.data_transformers.enable('custom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(files = ('data/ReviewAMT_500_t.csv', 'data/GayMarriage_400.csv', 'data/GunControl_400.csv')):\n",
    "    df_atm = pd.read_csv(files[0], sep='\\t')\n",
    "    df_gay = pd.read_csv(files[1], sep='\\t')\n",
    "    df_gun = pd.read_csv(files[2], sep='\\t')\n",
    "\n",
    "    df_atm.rename(columns = {'ReviewTopic': 'Topic'}, inplace=True)\n",
    "    df_atm['Task'] = df_atm['Task'].map(\n",
    "        {\n",
    "            \"Fake Review\": 'fake', \n",
    "            \"True Review\": 'true',\n",
    "            'Copy_1': 'copy_1',\n",
    "            'Copy_2': 'copy_2'\n",
    "        })\n",
    "    df_gay['Task'] = df_gay['Task'].map(\n",
    "        {\n",
    "            \"Fake Essay\": 'fake', \n",
    "            \"True Essay\": 'true',\n",
    "            'Copy_1': 'copy_1',\n",
    "            'Copy_2': 'copy_2'\n",
    "        }) \n",
    "    df_gun['Task'] = df_gun['Task'].map(\n",
    "        {\n",
    "            \"Fake Essay\": 'fake', \n",
    "            \"True Essay\": 'true',\n",
    "            'Copy_1': 'copy_1',\n",
    "            'Copy_2': 'copy_2'\n",
    "        }) \n",
    "    datasets = (df_atm, df_gay, df_gun)\n",
    "    df = pd.concat(\n",
    "        (dataset[[\n",
    "            'UserName', \n",
    "            'AccessKey', \n",
    "            'Topic', \n",
    "            'Task',\n",
    "            'ReviewText', \n",
    "            'ReviewMeta'\n",
    "        ]] for dataset in datasets),\n",
    "        ignore_index=True)\n",
    "    return df\n",
    "\n",
    "df = read_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5200 entries, 0 to 5199\nData columns (total 6 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   UserName    5200 non-null   object\n 1   AccessKey   5200 non-null   object\n 2   Topic       5200 non-null   object\n 3   Task        5200 non-null   object\n 4   ReviewText  5200 non-null   object\n 5   ReviewMeta  5200 non-null   object\ndtypes: object(6)\nmemory usage: 243.9+ KB\n"
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_keystroke(line):\n",
    "    res = line.split(' ')\n",
    "    if len(res) > 3:\n",
    "        return f'UNKNOWN: {line}'\n",
    "    \n",
    "    time, command, key = res\n",
    "    return (time, command, key, chr(int(key)))\n",
    "\n",
    "def code_to_str(keycode):\n",
    "    keycode = int(keycode)\n",
    "    mappings = {\n",
    "        16: 'shift',\n",
    "        8: 'backspace',\n",
    "        32: 'space',\n",
    "        188: 'comma',\n",
    "        190: 'dot'\n",
    "    }\n",
    "    return mappings.get(keycode, chr(keycode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque \n",
    "def process_keystrokes(inputs, humanize=False, distinguish_shift=True):      \n",
    "    MOUSE_UP = 'MouseUp'\n",
    "    KEY_DOWN = 'KeyDown'\n",
    "    KEY_UP = 'KeyUp'\n",
    "    TRANSITION_2 = 'transition_2'\n",
    "    dwells = {}\n",
    "    transitions_1 = {}\n",
    "    transitions_2 = {}\n",
    "    key_downs = {}\n",
    "    keys_queue = deque([])\n",
    "    last_key_up = None\n",
    "    \n",
    "    def record_key(code1, code2, value, collection):\n",
    "        key = \"\"\n",
    "        if collection is transitions_2:\n",
    "            key = key + \"-\"\n",
    "        if (16 in key_downs or last_key_up == 16) and code1 != 16 and distinguish_shift:\n",
    "            key = key + \"[shift]\"\n",
    "        if code2:\n",
    "            key = key + f\"{code1}_{code2}\"\n",
    "        else:\n",
    "            key = key + f\"{code1}\"\n",
    "\n",
    "        if key not in collection: \n",
    "            collection[key] = []\n",
    "        collection[key].append(value)\n",
    "\n",
    "    for keystroke in inputs.split(';'):\n",
    "        res = keystroke.split(' ')\n",
    "        \n",
    "        if len(res) < 3: continue  \n",
    "        if res[1] == 'MouseUp': continue\n",
    "\n",
    "        time, command, code = res\n",
    "        time = int(time)\n",
    "        code = int(code)\n",
    "        \n",
    "        if command == KEY_DOWN:\n",
    "            if keys_queue:\n",
    "                prev_code, prev_time_down, prev_time_up = keys_queue[0]\n",
    "\n",
    "                if prev_time_up: \n",
    "                    record_key(prev_code, code, time - prev_time_up, transitions_2)\n",
    "\n",
    "                record_key(prev_code, code, time - prev_time_down, transitions_1)\n",
    "            \n",
    "            key_downs[code] = time\n",
    "            keys_queue.appendleft([code, time, None])\n",
    "            \n",
    "        if command == KEY_UP:\n",
    "            following_key = None\n",
    "            for i_key in keys_queue:\n",
    "                if i_key[0] == code:\n",
    "                    i_key[2] = time\n",
    "                    record_key(code, None, time - i_key[1], dwells)\n",
    "                    \n",
    "                    if following_key and following_key[1] < i_key[2]:\n",
    "                        record_key(i_key[0], following_key[0], following_key[1] - i_key[2], transitions_2)\n",
    "                    break\n",
    "\n",
    "                following_key = i_key\n",
    "\n",
    "            if code in key_downs: del(key_downs[code])\n",
    "            last_key_up = code\n",
    "\n",
    "    if humanize:\n",
    "        new_dwells = {}\n",
    "        new_transitions_1 = {}\n",
    "        new_transitions_2 = {}\n",
    "        shift_h = \"[shift]\"\n",
    "\n",
    "        for key, inputs in dwells.items():\n",
    "            prefix = \"\"\n",
    "            if shift_h in key:\n",
    "                key = key[7:]\n",
    "                prefix = shift_h\n",
    "            new_key = prefix + f\"{code_to_str(int(key))}\"\n",
    "            new_dwells[new_key] = sorted(inputs)\n",
    "\n",
    "        for key, inputs in transitions_1.items():\n",
    "            try:\n",
    "                k1, k2 = key.split(\"_\")\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            prefix = \"\"\n",
    "            if shift_h in k1:\n",
    "                k1 = k1[7:]\n",
    "                prefix = shift_h\n",
    "\n",
    "            key = f\"{prefix}{code_to_str(int(k1))}_{code_to_str(int(k2))}\"\n",
    "            new_transitions_1[key] = sorted(inputs)\n",
    "        for key, inputs in transitions_2.items(): \n",
    "            try:\n",
    "                k1, k2 = key.split(\"_\")\n",
    "            except:\n",
    "                continue\n",
    "            k1 = k1[1:] # here is a \"-\" sign\n",
    "\n",
    "            prefix = \"\"\n",
    "            if shift_h in k1:\n",
    "                k1 = k1[7:]\n",
    "                prefix = shift_h\n",
    "\n",
    "            key = f\"-{prefix}{code_to_str(int(k1))}_{code_to_str(int(k2))}\"\n",
    "            new_transitions_2[key] = inputs #sorted(inputs)\n",
    "\n",
    "        return new_dwells, new_transitions_1, new_transitions_2\n",
    "\n",
    "    return dwells, transitions_1, transitions_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'A': [127, 151],\n '[shift]H': [135],\n '[shift]E': [152],\n '[shift]L': [110, 127],\n 'shift': [2600, 3400],\n '[shift]O': [159]}"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = \"1583128026026 KeyDown 65;1583128026177 KeyUp 65;1583128026810 KeyDown 65;1583128026937 KeyUp 65;1583128027529 KeyDown 16;1583128028034 KeyDown 72;1583128028169 KeyUp 72;1583128028801 KeyDown 69;1583128028953 KeyUp 69;1583128029298 KeyDown 76;1583128029408 KeyUp 76;1583128029586 KeyDown 76;1583128029713 KeyUp 76;1583128030929 KeyUp 16;1583128031681 KeyDown 16;1583128032402 KeyDown 79;1583128032561 KeyUp 79;1583128034281 KeyUp 16\"\n",
    "\n",
    "dwells, transitions_1, transitions_2 = process_keystrokes(ss, humanize=True)\n",
    "dwells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 2496 entries, 0 to 5199\nData columns (total 6 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   UserName    2496 non-null   object\n 1   AccessKey   2496 non-null   object\n 2   Topic       2496 non-null   object\n 3   Task        2496 non-null   object\n 4   ReviewText  2496 non-null   object\n 5   ReviewMeta  2496 non-null   object\ndtypes: object(6)\nmemory usage: 136.5+ KB\n"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# def split_datasets(df):\n",
    "#     df1 = df.loc[df['Task'] == 'copy_1']\n",
    "#     df1.drop_duplicates(subset =\"UserName\", keep = False, inplace = True) \n",
    "\n",
    "#     df2 = df.loc[df['Task'] == 'copy_2']\n",
    "#     df2.drop_duplicates(subset =\"UserName\", keep = False, inplace = True) \n",
    "\n",
    "#     train_X, val_X = train_test_split(df1, test_size=0.2, random_state=42)\n",
    "#     train_y = df2[df2['UserName'].isin(train_X['UserName'].tolist())]\n",
    "#     val_y = df2[df2['UserName'].isin(val_X['UserName'].tolist())]\n",
    "#     return train_X, val_X, train_y, val_y\n",
    "\n",
    "def split_datasets(df):\n",
    "    df_new = df.drop_duplicates(subset =[\"UserName\", \"Task\"], keep = False, inplace = False) \n",
    "    df1 = df_new.loc[df['Task'].isin(['copy_1', 'copy_2', 'true'])]\n",
    "    df2 = df_new.loc[df['Task'] == 'fake']\n",
    "    return df1, None, df2, None\n",
    "\n",
    "df_train, df_val, train_y, val_y = split_datasets(df)\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(14.4, 8.2365041127896, 67.84)"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def timestamp_values(array, coef=1.5):\n",
    "    array = np.array(array)\n",
    "    q1 = np.quantile(array, 0.25)\n",
    "    q3 = np.quantile(array, 0.75)\n",
    "    iqr = q3 - q1\n",
    "    array = array[(array > (q1 - coef * iqr)) & (array < (q3 + coef * iqr))]\n",
    "    return array.mean(), array.std(), array.var()\n",
    "\n",
    "timestamp_values([1, 11, 23, 14, 23, 1111])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = ['T_H', 'H_E', 'A_N', 'T_space', 'R_E', 'I_N', 'E', 'A', 'R', 'I', 'O', 'T', 'N']\n",
    "FEATURES = [\n",
    "    'S_space', 'space_A', 'D_space', 'E_space', 'space_T', 'backspace_backspace', \n",
    "    'T_H', 'H_E', 'A_N', 'T_space', 'R_E', 'I_N', \n",
    "    'E', 'A', 'R', 'I', 'O', 'T', 'N', 'S', 'space'\n",
    "    ]\n",
    "\n",
    "FEATURES = ['backspace_backspace', \"E_space\", \"space_T\", \"T_H\", \"space_A\", \"S_space\", \"T_space\", \"H_E\", \"D_space\", \"A_N\", \"I_N\", \"R_E\", \"N_space\", \"E_R\", \"Y_space\", \"space_I\", \"space_O\", \"O_space\", \"space_W\", \"space_S\", \"O_N\", \"N_D\", \"E_N\", \"R_space\", \"O_U\", \"space\", \"E\", \"backspace\", \"T\", \"A\", \"O\", \"I\", \"N\", \"S\", \"R\", \"H\", \"L\", \"D\", \"U\", \"C\", \"M\", \"G\", \"Y\", \"F\", \"W\", \"P\", \"B\", \"comma\", \"V\", \"dot\", \"K\"]\n",
    "\n",
    "USE_TRANSITION_2 = True\n",
    "N_NEIGHBORS=3\n",
    "\n",
    "def process_and_unite_keystrokes(\n",
    "    inputs, \n",
    "    humanize=True, \n",
    "    distinguish_shift=True,\n",
    "    normalizator = timestamp_values,\n",
    "    normalizator_coef = 1.5,\n",
    "    transition_2=False): \n",
    "    a,b,c = process_keystrokes(inputs, humanize, distinguish_shift)\n",
    "    raw_data = {**a , **b, **c}\n",
    "    res = {}\n",
    "\n",
    "    features = FEATURES\n",
    "    if transition_2:\n",
    "        features = list(map(lambda x: x if \"_\" not in x else f\"-{x}\", features))\n",
    "\n",
    "    for feature in features:\n",
    "        if feature in raw_data: \n",
    "            mean, std, var = normalizator(raw_data[feature], normalizator_coef)\n",
    "        else: \n",
    "            mean, std, var = None, None, None\n",
    "\n",
    "        res[f\"{feature}_mean\"] = mean \n",
    "        res[f\"{feature}_std\"] = std \n",
    "        # res[f\"{feature}_var\"] = var\n",
    "\n",
    "    return res\n",
    "\n",
    "def mutate_dataset(df, \n",
    "    user_id_column = \"UserName\", \n",
    "    keystrokes_column=\"ReviewMeta\", \n",
    "    transition_2=False):\n",
    "    res = []\n",
    "    for index, inputs in df.iterrows():\n",
    "        data = process_and_unite_keystrokes(inputs[keystrokes_column], transition_2=transition_2)\n",
    "        res.append({'user_id': inputs[user_id_column], **data})\n",
    "    return pd.DataFrame(res)\n",
    "\n",
    "def standartize_dataset(res):\n",
    "    modifiers = {}\n",
    "    for column in res.columns.difference(['user_id']):\n",
    "        mean_v = res[column].mean()\n",
    "\n",
    "        # Fill n/a values with mean\n",
    "        res[column].fillna(mean_v, inplace=True)\n",
    "\n",
    "        min_v = res[column].min()\n",
    "        max_v = res[column].max()\n",
    "        res[column] = res[column].apply(lambda x: (x - min_v)/(max_v - min_v))\n",
    "\n",
    "        # Save modifiers so that they could be applied to \n",
    "        modifiers[column] = { 'mean': mean_v, 'min': min_v, 'max': max_v }\n",
    "\n",
    "    return res, modifiers\n",
    "\n",
    "def standartize_by_modifiers(res, modifiers, features = FEATURES): \n",
    "    for column in res.columns.difference(['user_id']):\n",
    "        # Fill n/a values with mean\n",
    "        res[column].fillna(modifiers[column]['mean'], inplace=True)\n",
    "\n",
    "        min_v = modifiers[column]['min']\n",
    "        max_v = modifiers[column]['max']\n",
    "        res[column] = res[column].apply(lambda x: (x - min_v)/(max_v - min_v))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>-backspace_backspace_mean</th>\n      <th>-backspace_backspace_std</th>\n      <th>-E_space_mean</th>\n      <th>-E_space_std</th>\n      <th>-space_T_mean</th>\n      <th>-space_T_std</th>\n      <th>-T_H_mean</th>\n      <th>-T_H_std</th>\n      <th>-space_A_mean</th>\n      <th>...</th>\n      <th>B_mean</th>\n      <th>B_std</th>\n      <th>comma_mean</th>\n      <th>comma_std</th>\n      <th>V_mean</th>\n      <th>V_std</th>\n      <th>dot_mean</th>\n      <th>dot_std</th>\n      <th>K_mean</th>\n      <th>K_std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A002160837SWJFPIAI7L7</td>\n      <td>0.014156</td>\n      <td>0.005808</td>\n      <td>0.061186</td>\n      <td>0.020494</td>\n      <td>0.123876</td>\n      <td>0.077483</td>\n      <td>0.135681</td>\n      <td>0.166298</td>\n      <td>0.083225</td>\n      <td>...</td>\n      <td>0.637563</td>\n      <td>0.168824</td>\n      <td>0.321300</td>\n      <td>0.216331</td>\n      <td>0.401061</td>\n      <td>0.349531</td>\n      <td>0.402466</td>\n      <td>0.528400</td>\n      <td>0.437353</td>\n      <td>0.127536</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A0436270XG2E3RS5T61O</td>\n      <td>0.014554</td>\n      <td>0.005186</td>\n      <td>0.113482</td>\n      <td>0.023985</td>\n      <td>0.130576</td>\n      <td>0.020893</td>\n      <td>0.608480</td>\n      <td>0.074421</td>\n      <td>0.074955</td>\n      <td>...</td>\n      <td>0.440343</td>\n      <td>0.137301</td>\n      <td>0.776655</td>\n      <td>0.013702</td>\n      <td>0.473086</td>\n      <td>0.011665</td>\n      <td>0.515642</td>\n      <td>0.375286</td>\n      <td>0.369412</td>\n      <td>0.008588</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A109TOWKB3DY3P</td>\n      <td>0.013894</td>\n      <td>0.002557</td>\n      <td>0.052018</td>\n      <td>0.014546</td>\n      <td>0.113401</td>\n      <td>0.049800</td>\n      <td>0.531242</td>\n      <td>0.053522</td>\n      <td>0.038106</td>\n      <td>...</td>\n      <td>0.683885</td>\n      <td>0.080783</td>\n      <td>0.429603</td>\n      <td>0.128250</td>\n      <td>0.577331</td>\n      <td>0.333951</td>\n      <td>0.489142</td>\n      <td>0.310829</td>\n      <td>0.469412</td>\n      <td>0.011569</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 103 columns</p>\n</div>",
      "text/plain": "                 user_id  -backspace_backspace_mean  -backspace_backspace_std  \\\n0  A002160837SWJFPIAI7L7                   0.014156                  0.005808   \n1   A0436270XG2E3RS5T61O                   0.014554                  0.005186   \n2         A109TOWKB3DY3P                   0.013894                  0.002557   \n\n   -E_space_mean  -E_space_std  -space_T_mean  -space_T_std  -T_H_mean  \\\n0       0.061186      0.020494       0.123876      0.077483   0.135681   \n1       0.113482      0.023985       0.130576      0.020893   0.608480   \n2       0.052018      0.014546       0.113401      0.049800   0.531242   \n\n   -T_H_std  -space_A_mean  ...    B_mean     B_std  comma_mean  comma_std  \\\n0  0.166298       0.083225  ...  0.637563  0.168824    0.321300   0.216331   \n1  0.074421       0.074955  ...  0.440343  0.137301    0.776655   0.013702   \n2  0.053522       0.038106  ...  0.683885  0.080783    0.429603   0.128250   \n\n     V_mean     V_std  dot_mean   dot_std    K_mean     K_std  \n0  0.401061  0.349531  0.402466  0.528400  0.437353  0.127536  \n1  0.473086  0.011665  0.515642  0.375286  0.369412  0.008588  \n2  0.577331  0.333951  0.489142  0.310829  0.469412  0.011569  \n\n[3 rows x 103 columns]"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_new, modifiers = standartize_dataset(mutate_dataset(df_train, transition_2=USE_TRANSITION_2))\n",
    "train_y_new = standartize_by_modifiers(mutate_dataset(train_y, transition_2=USE_TRANSITION_2), modifiers)\n",
    "train_y_new.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "KNN Score: 0.9350961538461539\n"
    },
    {
     "data": {
      "text/plain": "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n                     metric_params=None, n_jobs=None, n_neighbors=1, p=1,\n                     weights='uniform')"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def knn_model(df, df_new, y_column): \n",
    "    knn = KNeighborsClassifier(n_neighbors=1, p=1)\n",
    "    knn.fit(df[df.columns.difference([y_column])], df[y_column])\n",
    "    score = knn.score(df_new[df_new.columns.difference([y_column])], df_new[y_column])\n",
    "    print(f\"KNN Score: {score}\")\n",
    "    return knn\n",
    "\n",
    "def knn_pca_model(df, df_new, y_column):\n",
    "    pca = PCA(n_components = 0.99)\n",
    "    knn = KNeighborsClassifier(n_neighbors=3, p=1)\n",
    "    train_data = df[df.columns.difference([y_column])]\n",
    "    train_targets = df[y_column]\n",
    "    print(train_data.shape)\n",
    "\n",
    "    pca.fit(train_data, train_targets)\n",
    "    knn.fit(pca.transform(train_data), train_targets)\n",
    "\n",
    "    test_data = df_new[df_new.columns.difference([y_column])]\n",
    "    print(test_data.shape)\n",
    "    score = knn.score(pca.transform(test_data), df_new[y_column])\n",
    "    print(f\"KNN Score: {score}\")\n",
    "    return knn, pca\n",
    "\n",
    "knn = knn_model(df_train_new, train_y_new, y_column='user_id')\n",
    "# knn, pca = knn_pca_model(df_train_new, train_y_new, y_column='user_id')\n",
    "knn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}