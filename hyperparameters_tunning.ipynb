{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tabulate\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DataTransformerRegistry.enable('default')"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "alt.data_transformers.enable('default', max_rows=None) \n",
    "# alt.renderers.enable('default')\n",
    "# alt.renderers.enable('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DataTransformerRegistry.enable('custom')"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Save temp altair json files in separate folder\n",
    "os.makedirs('tmp/altdata', exist_ok=True)\n",
    "\n",
    "def custom(data):\n",
    "    return alt.pipe(data, alt.to_json(filename='tmp/altdata/{prefix}-{hash}.{extension}') )\n",
    "\n",
    "alt.data_transformers.register('custom', custom)\n",
    "alt.data_transformers.enable('custom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_datasets(datasets):\n",
    "    return pd.concat(\n",
    "        (dataset[[\n",
    "            'UserName', \n",
    "            'AccessKey', \n",
    "            'Topic', \n",
    "            'Task',\n",
    "            'ReviewText', \n",
    "            'ReviewMeta'\n",
    "        ]] for dataset in datasets),\n",
    "        ignore_index=True)\n",
    "\n",
    "def read_dataset(files = ('data/ReviewAMT_500_t.csv', 'data/GayMarriage_400.csv', 'data/GunControl_400.csv')):\n",
    "    df_atm = pd.read_csv(files[0], sep='\\t')\n",
    "    df_gay = pd.read_csv(files[1], sep='\\t')\n",
    "    df_gun = pd.read_csv(files[2], sep='\\t')\n",
    "\n",
    "    df_atm.rename(columns = {'ReviewTopic': 'Topic'}, inplace=True)\n",
    "    df_atm['Task'] = df_atm['Task'].map(\n",
    "        {\n",
    "            \"Fake Review\": 'fake', \n",
    "            \"True Review\": 'true',\n",
    "            'Copy_1': 'copy_1',\n",
    "            'Copy_2': 'copy_2'\n",
    "        })\n",
    "    df_gay['Task'] = df_gay['Task'].map(\n",
    "        {\n",
    "            \"Fake Essay\": 'fake', \n",
    "            \"True Essay\": 'true',\n",
    "            'Copy_1': 'copy_1',\n",
    "            'Copy_2': 'copy_2'\n",
    "        }) \n",
    "    df_gun['Task'] = df_gun['Task'].map(\n",
    "        {\n",
    "            \"Fake Essay\": 'fake', \n",
    "            \"True Essay\": 'true',\n",
    "            'Copy_1': 'copy_1',\n",
    "            'Copy_2': 'copy_2'\n",
    "        }) \n",
    "    return concat_datasets((df_atm, df_gay, df_gun))\n",
    "\n",
    "df = read_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5200 entries, 0 to 5199\nData columns (total 6 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   UserName    5200 non-null   object\n 1   AccessKey   5200 non-null   object\n 2   Topic       5200 non-null   object\n 3   Task        5200 non-null   object\n 4   ReviewText  5200 non-null   object\n 5   ReviewMeta  5200 non-null   object\ndtypes: object(6)\nmemory usage: 243.9+ KB\n"
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                          ReviewText  \\\n0  Linear algebra is central to almost all areas ...   \n1  Linear algebra is central to almost all areas ...   \n2  Linear algebra is central to almost all areas ...   \n\n                                          ReviewMeta  \\\n0  1582990688239 KeyDown 16;1582990688600 KeyDown...   \n1  1582996141506 KeyDown 16;1582996141595 KeyDown...   \n2  1582996489340 KeyDown 16;1582996489541 KeyDown...   \n\n                              AccessKey                              UserName  \\\n0  9d891be4-e43e-49f9-88bb-25314e670850  9d891be4-e43e-49f9-88bb-25314e670850   \n1  9d891be4-e43e-49f9-88bb-25314e670850  9d891be4-e43e-49f9-88bb-25314e670850   \n2  97fc22cf-aa61-4dcf-91a8-97d8fbf4a983  97fc22cf-aa61-4dcf-91a8-97d8fbf4a983   \n\n     Task Topic  \n0  copy_1    LA  \n1  copy_2    LA  \n2  copy_1    LA  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ReviewText</th>\n      <th>ReviewMeta</th>\n      <th>AccessKey</th>\n      <th>UserName</th>\n      <th>Task</th>\n      <th>Topic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Linear algebra is central to almost all areas ...</td>\n      <td>1582990688239 KeyDown 16;1582990688600 KeyDown...</td>\n      <td>9d891be4-e43e-49f9-88bb-25314e670850</td>\n      <td>9d891be4-e43e-49f9-88bb-25314e670850</td>\n      <td>copy_1</td>\n      <td>LA</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Linear algebra is central to almost all areas ...</td>\n      <td>1582996141506 KeyDown 16;1582996141595 KeyDown...</td>\n      <td>9d891be4-e43e-49f9-88bb-25314e670850</td>\n      <td>9d891be4-e43e-49f9-88bb-25314e670850</td>\n      <td>copy_2</td>\n      <td>LA</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Linear algebra is central to almost all areas ...</td>\n      <td>1582996489340 KeyDown 16;1582996489541 KeyDown...</td>\n      <td>97fc22cf-aa61-4dcf-91a8-97d8fbf4a983</td>\n      <td>97fc22cf-aa61-4dcf-91a8-97d8fbf4a983</td>\n      <td>copy_1</td>\n      <td>LA</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "source": [
    "def read_group_sessions(name='data/keystroke_sessions-2020-03-20.csv'):\n",
    "    _a = pd.read_csv(name)\n",
    "    # _a.rename(columns={\"AccessKey\": \"UserName\", }\n",
    "    _a['UserName'] = _a['AccessKey']\n",
    "    _a.drop(columns=['attempt_id', 'ReviewDate'], inplace=True)\n",
    "    _a['Task'] = ''\n",
    "    _a['Topic'] = 'LA'\n",
    "    attempts = {}\n",
    "    for i, row in _a.iterrows():\n",
    "        key = row['UserName']\n",
    "        if key not in attempts: attempts[key] = 0\n",
    "        attempts[key] += 1\n",
    "        _a.loc[i, 'Task'] = f\"copy_{attempts[key]}\"\n",
    "\n",
    "    return _a\n",
    "\n",
    "def add_text_length_column(df):\n",
    "    df['TextLenght'] = df.apply(lambda x: len(x['ReviewText'].split()), axis = 1)\n",
    "\n",
    "df_sessions = read_group_sessions()\n",
    "df_sessions.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_keystroke(line):\n",
    "    res = line.split(' ')\n",
    "    if len(res) > 3:\n",
    "        return f'UNKNOWN: {line}'\n",
    "    \n",
    "    time, command, key = res\n",
    "    return (time, command, key, chr(int(key)))\n",
    "\n",
    "def code_to_str(keycode):\n",
    "    keycode = int(keycode)\n",
    "    mappings = {\n",
    "        16: 'shift',\n",
    "        8: 'backspace',\n",
    "        32: 'space',\n",
    "        188: 'comma',\n",
    "        190: 'dot'\n",
    "    }\n",
    "    return mappings.get(keycode, chr(keycode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque \n",
    "\n",
    "def process_keystrokes(inputs, humanize=False, distinguish_shift=True, small_transitions=True):      \n",
    "    MOUSE_UP = 'MouseUp'\n",
    "    KEY_DOWN = 'KeyDown'\n",
    "    KEY_UP = 'KeyUp'\n",
    "    TRANSITION_2 = 'transition_2'\n",
    "    dwells = {}\n",
    "    transitions_1 = {}\n",
    "    transitions_2 = {}\n",
    "    key_downs = {}\n",
    "    keys_queue = deque([])\n",
    "    last_key_up = None\n",
    "\n",
    "    def correct_transitions():\n",
    "        if small_transitions:\n",
    "            return transitions_2\n",
    "        else:\n",
    "            return transitions_1\n",
    "    \n",
    "    def record_key(code1, code2, value, collection):\n",
    "        key = \"\"\n",
    "        if (16 in key_downs or last_key_up == 16) and code1 != 16 and distinguish_shift:\n",
    "            key = key + \"[shift]\"\n",
    "        if code2:\n",
    "            key = key + f\"{code1}_{code2}\"\n",
    "        else:\n",
    "            key = key + f\"{code1}\"\n",
    "\n",
    "        if key not in collection: \n",
    "            collection[key] = []\n",
    "        collection[key].append(value)\n",
    "\n",
    "    for keystroke in inputs.split(';'):\n",
    "        res = keystroke.split(' ')\n",
    "        \n",
    "        if len(res) < 3: continue  \n",
    "        if res[1] == 'MouseUp': continue\n",
    "\n",
    "        time, command, code = res\n",
    "        time = int(time)\n",
    "        code = int(code)\n",
    "        \n",
    "        if command == KEY_DOWN:\n",
    "            if keys_queue:\n",
    "                prev_code, prev_time_down, prev_time_up = keys_queue[0]\n",
    "\n",
    "                if prev_time_up: \n",
    "                    record_key(prev_code, code, time - prev_time_up, transitions_2)\n",
    "\n",
    "                record_key(prev_code, code, time - prev_time_down, transitions_1)\n",
    "            \n",
    "            key_downs[code] = time\n",
    "            keys_queue.appendleft([code, time, None])\n",
    "            \n",
    "        if command == KEY_UP:\n",
    "            following_key = None\n",
    "            for i_key in keys_queue:\n",
    "                if i_key[0] == code:\n",
    "                    i_key[2] = time\n",
    "                    record_key(code, None, time - i_key[1], dwells)\n",
    "                    \n",
    "                    if following_key and following_key[1] < i_key[2]:\n",
    "                        record_key(i_key[0], following_key[0], following_key[1] - i_key[2], transitions_2)\n",
    "                    break\n",
    "\n",
    "                following_key = i_key\n",
    "\n",
    "            if code in key_downs: del(key_downs[code])\n",
    "            last_key_up = code\n",
    "\n",
    "    if humanize:\n",
    "        new_dwells = {}\n",
    "        new_transitions = {}\n",
    "        shift_h = \"[shift]\"\n",
    "\n",
    "        for key, inputs in dwells.items():\n",
    "            prefix = \"\"\n",
    "            if shift_h in key:\n",
    "                key = key[7:]\n",
    "                prefix = shift_h\n",
    "            new_key = prefix + f\"{code_to_str(int(key))}\"\n",
    "            new_dwells[new_key] = sorted(inputs)\n",
    "\n",
    "        for key, inputs in correct_transitions().items():\n",
    "            try:\n",
    "                k1, k2 = key.split(\"_\")\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            prefix = \"\"\n",
    "            if shift_h in k1:\n",
    "                k1 = k1[7:]\n",
    "                prefix = shift_h\n",
    "\n",
    "            key = f\"{prefix}{code_to_str(int(k1))}_{code_to_str(int(k2))}\"\n",
    "            new_transitions[key] = sorted(inputs)\n",
    "\n",
    "        return new_dwells, new_transitions\n",
    "\n",
    "    return dwells, correct_transitions()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'A': [127, 151], '[shift]H': [135], '[shift]E': [152], '[shift]L': [110, 127], 'shift': [2600, 3400], '[shift]O': [159]}\n{'A_A': [633], 'A_shift': [592], '[shift]H_E': [632], '[shift]E_L': [345], '[shift]L_L': [178], 'shift_H': [-2895], '[shift]L_shift': [1968], 'shift_O': [-1879]}\n"
    }
   ],
   "source": [
    "ss = \"1583128026026 KeyDown 65;1583128026177 KeyUp 65;1583128026810 KeyDown 65;1583128026937 KeyUp 65;1583128027529 KeyDown 16;1583128028034 KeyDown 72;1583128028169 KeyUp 72;1583128028801 KeyDown 69;1583128028953 KeyUp 69;1583128029298 KeyDown 76;1583128029408 KeyUp 76;1583128029586 KeyDown 76;1583128029713 KeyUp 76;1583128030929 KeyUp 16;1583128031681 KeyDown 16;1583128032402 KeyDown 79;1583128032561 KeyUp 79;1583128034281 KeyUp 16\"\n",
    "\n",
    "dwells, transitions = process_keystrokes(ss, humanize=True, small_transitions=True)\n",
    "print(dwells)\n",
    "print(transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 3200 entries, 0 to 5229\nData columns (total 6 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   UserName    3200 non-null   object\n 1   AccessKey   3200 non-null   object\n 2   Topic       3200 non-null   object\n 3   Task        3200 non-null   object\n 4   ReviewText  3200 non-null   object\n 5   ReviewMeta  3200 non-null   object\ndtypes: object(6)\nmemory usage: 175.0+ KB\n"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# def split_datasets(df):\n",
    "#     df1 = df.loc[df['Task'] == 'copy_1']\n",
    "#     df1.drop_duplicates(subset =\"UserName\", keep = False, inplace = True) \n",
    "\n",
    "#     df2 = df.loc[df['Task'] == 'copy_2']\n",
    "#     df2.drop_duplicates(subset =\"UserName\", keep = False, inplace = True) \n",
    "\n",
    "#     train_X, val_X = train_test_split(df1, test_size=0.2, random_state=42)\n",
    "#     train_y = df2[df2['UserName'].isin(train_X['UserName'].tolist())]\n",
    "#     val_y = df2[df2['UserName'].isin(val_X['UserName'].tolist())]\n",
    "#     return train_X, val_X, train_y, val_y\n",
    "\n",
    "def split_datasets(df):\n",
    "    df_new = df.copy()\n",
    "    df_new = df_new.drop_duplicates(subset =[\"UserName\", \"Task\"], keep = 'first', inplace = False) \n",
    "    # df_new = df_new.drop_duplicates(subset =[\"UserName\", \"Task\"], keep = False, inplace = False)\n",
    "    test_column = 'copy_2'\n",
    "    # test_column = 'fake'\n",
    "    df1 = df_new.loc[df['Task'] != test_column]\n",
    "    # df1 = df_new.loc[df['Task'] == 'copy_1']\n",
    "    df2 = df_new.loc[df['Task'] == test_column]\n",
    "    return df1, None, df2, None\n",
    "\n",
    "df_train, df_val, train_y, val_y = split_datasets(concat_datasets((df, df_sessions)))\n",
    "# df_train, df_val, train_y, val_y = split_datasets(df)\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = ['space', 'E', 'T', 'A', 'O', 'backspace', 'N', 'I', 'S', 'R', 'H',\n",
    "       'backspace_backspace', 'L', 'E_space', 'D', 'space_T', 'U', 'C',\n",
    "       'space_A', 'T_H', 'S_space', 'M', 'shift', 'G', 'Y', 'T_space',\n",
    "       'F', 'H_E', 'W', 'P', 'D_space', 'A_N', 'I_N', 'R_E', 'N_space',\n",
    "       'Y_space', 'E_R', 'B', 'space_shift', 'space_I', 'space_O',\n",
    "       'space_W', 'V', 'dot', 'space_S', 'O_space', 'O_N', 'N_D', 'E_N',\n",
    "       'R_space', 'dot_space', 'A_T', 'O_U', 'T_O', 'space_C', 'I_T',\n",
    "       'space_B', 'A_R', 'E_S', 'H_A', 'I_S', 'V_E', 'comma', 'A_L',\n",
    "       'space_M', 'space_F', 'comma_space', 'R_I', 'O_R',\n",
    "       'space_backspace', 'L_E', 'S_T', 'N_T', 'N_G', 'space_P',\n",
    "       'space_H', 'S_E', 'T_I', 'A_space', 'M_E', 'space_G', 'T_E', 'E_D',\n",
    "       'F_space', 'L_space', 'E_A', 'K', 'A_S', 'B_E', 'M_A', 'L_L',\n",
    "       'G_space', '[shift]space', '[shift]I', 'space_R', 'space_D', 'U_N',\n",
    "       'O_F', 'H_O', 'H_I', 'C_O', 'shift_I', 'N_E', 'space_L', 'R_O',\n",
    "       'space_N', 'O_M', 'O_T', 'L_I', 'space_E', 'D_E', '[shift]T',\n",
    "       'N_S', 'I_C', 'C_E', 'L_Y', 'T_A', 'G_E', 'I_O', 'U_R', 'E_L',\n",
    "       'F_O', 'U_S', 'N_O', 'P_E', 'H_space', 'S_O', 'I_L', 'W_E',\n",
    "       'shift_T', 'C_H', 'C_A', 'P_L', 'U_L', 'E_T', 'W_A', 'A_Y', 'T_R',\n",
    "       'L_D', 'U_T', 'L_A', 'R_A', 'E_C', 'E_E', 'I_E', 'W_I',\n",
    "       '[shift]space_shift', 'backspace_space', 'G_U', 'W_H', 'S_H',\n",
    "       'A_V', 'A_C', 'E_backspace', 'O_O', 'space_space', 'O_P', 'R_Y',\n",
    "       'O_W', 'I_A', 'R_R', 'Þ', 'L_O', 'S_I', 'O_L', 'A_G', 'D_I', 'I_G',\n",
    "       'E_V', 'A_M', 'G_H', 'W_O', 'Y_O', 'M_O', 'backspace_shift', 'O_S',\n",
    "       'G_A', 'P_O', 'K_E', 'R_S', 'backspace_E', 'P_R', 'S_dot', 'E_dot',\n",
    "       'I_M', 'I_R', 'M_space', 'S_A', 'backspace_T', 'backspace_A', 'X',\n",
    "       'C_I', 'space_Y', 'E_Y', 'F_E', 'O_D', 'D_O', 'space_U', 'T_S',\n",
    "       'A_D']\n",
    "\n",
    "DISTINGUISH_SHIFT=True\n",
    "USE_TRANSITION_2 = True \n",
    "N_NEIGHBORS=1\n",
    "FEATURES_COUNTER = {}\n",
    "TRACK_FEATURES_COUNT = False\n",
    "NORMALIZATOR_COEF=1.5\n",
    "REMOVE_OUTLIERS = True\n",
    "USE_MEAN = False \n",
    "USE_MEDIAN = True\n",
    "USE_STD = False\n",
    "USE_VARIANCE = False \n",
    "DISTANCE_MEASURE = 1 # 1 - manhattan, 2 - euql.\n",
    "from sklearn import impute, preprocessing\n",
    "DATA_IMPUTER = impute.SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "# DATA_TRANSFORMER = preprocessing.MaxAbsScaler(), preprocessing.RobustScaler(), preprocessing.Normalizer(), preprocessing.MinMaxScaler(), preprocessing.StandardScaler()\n",
    "DATA_TRANSFORMER = preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_raw_data_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp_values(array, coef=1.5, original_median=True):\n",
    "    array = np.array(array)\n",
    "\n",
    "    if REMOVE_OUTLIERS:\n",
    "        q1 = np.quantile(array, 0.25)\n",
    "        q3 = np.quantile(array, 0.75)\n",
    "        iqr = q3 - q1\n",
    "        array = array[(array > (q1 - coef * iqr)) & (array < (q3 + coef * iqr))]\n",
    "\n",
    "    return array.mean(), np.median(array), array.std(), array.var()\n",
    "\n",
    "def process_and_unite_keystrokes(inputs, index, features=FEATURES): \n",
    "    humanize = True\n",
    "    if index not in cached_raw_data_dict:\n",
    "        a,b = process_keystrokes(inputs, humanize, DISTINGUISH_SHIFT, small_transitions=USE_TRANSITION_2)\n",
    "        raw_data = {**a , **b}\n",
    "        cached_raw_data_dict[index]=raw_data \n",
    "    else: \n",
    "        raw_data = cached_raw_data_dict[index]\n",
    "    res = {}\n",
    "\n",
    "    for feature in features:\n",
    "        if feature in raw_data: \n",
    "            mean, median, std, var = timestamp_values(raw_data[feature], NORMALIZATOR_COEF)\n",
    "        else: \n",
    "            mean, median, std, var = None, None, None, None\n",
    "\n",
    "        if USE_MEAN: res[f\"{feature}_mean\"] = mean \n",
    "        if USE_MEDIAN: res[f\"{feature}_median\"] = median \n",
    "        if USE_STD: res[f\"{feature}_std\"] = std \n",
    "        if USE_VARIANCE: res[f\"{feature}_var\"] = var\n",
    "\n",
    "    if TRACK_FEATURES_COUNT:\n",
    "        # Save statistics of appearance of each key\n",
    "        for key, timestamps in raw_data.items():\n",
    "            if key not in FEATURES_COUNTER: FEATURES_COUNTER[key] = 0\n",
    "            FEATURES_COUNTER[key] += len(timestamps)\n",
    "\n",
    "    return res\n",
    "\n",
    "def mutate_dataset(df, \n",
    "    user_id_column = \"UserName\", \n",
    "    keystrokes_column=\"ReviewMeta\", \n",
    "    transition_2=False,\n",
    "    features=FEATURES):\n",
    "    res = []\n",
    "    for index, inputs in df.iterrows():\n",
    "        data = process_and_unite_keystrokes(inputs[keystrokes_column], index, features)\n",
    "        res.append({'user_id': inputs[user_id_column], **data})\n",
    "    return pd.DataFrame(res)\n",
    "\n",
    "def to_pandas_dataframe(res_copy, res, y_column='user_id'):\n",
    "    res_copy = pd.DataFrame(res_copy, columns = res.columns.difference([y_column]))\n",
    "    res_copy['user_id'] = res['user_id']\n",
    "    return res_copy\n",
    "\n",
    "def standartize_dataset(res, imputer=DATA_IMPUTER, transformer=DATA_TRANSFORMER):\n",
    "    from sklearn import impute, preprocessing\n",
    "\n",
    "    res_copy = res[res.columns.difference(['user_id'])]\n",
    "    res_copy = imputer.fit_transform(res_copy)\n",
    "    res_copy = transformer.fit_transform(res_copy)\n",
    "\n",
    "    return to_pandas_dataframe(res_copy, res), imputer, transformer\n",
    "\n",
    "def standartize_by_modifiers(res, imputer, transformer): \n",
    "    res_copy = res[res.columns.difference(['user_id'])]\n",
    "    res_copy = imputer.transform(res_copy)\n",
    "    res_copy = transformer.transform(res_copy)\n",
    "    return to_pandas_dataframe(res_copy, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Done!\n"
    }
   ],
   "source": [
    "n_features = 40\n",
    "df_train_mutated = mutate_dataset(df_train, transition_2=USE_TRANSITION_2, features=FEATURES[:n_features])\n",
    "train_y_mutated = mutate_dataset(train_y, transition_2=USE_TRANSITION_2,features=FEATURES[:n_features])\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   A_N_median  A_median  B_median  C_median  D_median  D_space_median  \\\n0    0.634472  0.767679  0.639647  0.847244  0.313917         -0.4833   \n\n   E_R_median  E_median  E_space_median  F_median  ...  Y_space_median  \\\n0   -0.631284    0.4811       -0.564155  0.180844  ...       -0.325655   \n\n   backspace_backspace_median  backspace_median  shift_median  space_A_median  \\\n0                   -0.142888         -0.242862     -0.294315       -0.337723   \n\n   space_I_median  space_T_median  space_median  space_shift_median  \\\n0       -0.225074       -0.089442     -0.265797           -0.278977   \n\n                 user_id  \n0  A002160837SWJFPIAI7L7  \n\n[1 rows x 41 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A_N_median</th>\n      <th>A_median</th>\n      <th>B_median</th>\n      <th>C_median</th>\n      <th>D_median</th>\n      <th>D_space_median</th>\n      <th>E_R_median</th>\n      <th>E_median</th>\n      <th>E_space_median</th>\n      <th>F_median</th>\n      <th>...</th>\n      <th>Y_space_median</th>\n      <th>backspace_backspace_median</th>\n      <th>backspace_median</th>\n      <th>shift_median</th>\n      <th>space_A_median</th>\n      <th>space_I_median</th>\n      <th>space_T_median</th>\n      <th>space_median</th>\n      <th>space_shift_median</th>\n      <th>user_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.634472</td>\n      <td>0.767679</td>\n      <td>0.639647</td>\n      <td>0.847244</td>\n      <td>0.313917</td>\n      <td>-0.4833</td>\n      <td>-0.631284</td>\n      <td>0.4811</td>\n      <td>-0.564155</td>\n      <td>0.180844</td>\n      <td>...</td>\n      <td>-0.325655</td>\n      <td>-0.142888</td>\n      <td>-0.242862</td>\n      <td>-0.294315</td>\n      <td>-0.337723</td>\n      <td>-0.225074</td>\n      <td>-0.089442</td>\n      <td>-0.265797</td>\n      <td>-0.278977</td>\n      <td>A002160837SWJFPIAI7L7</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 41 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 310
    }
   ],
   "source": [
    "df_train_new, imputer, transformer = standartize_dataset(df_train_mutated)\n",
    "train_y_new = standartize_by_modifiers(train_y_mutated, imputer, transformer)\n",
    "\n",
    "train_y_new.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(3200, 41)\nKNN Score: 0.9607843137254902\n(3200, 18)\n(1071, 18)\nKNN+PCA Score: 0.7973856209150327\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n                     metric_params=None, n_jobs=None, n_neighbors=1, p=1,\n                     weights='uniform')"
     },
     "metadata": {},
     "execution_count": 311
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def knn_model(df, df_new, y_column): \n",
    "    knn = KNeighborsClassifier(n_neighbors=N_NEIGHBORS, p=DISTANCE_MEASURE)\n",
    "    knn.fit(df[df.columns.difference([y_column])], df[y_column])\n",
    "    score = knn.score(df_new[df_new.columns.difference([y_column])], df_new[y_column])\n",
    "    print(df.shape)\n",
    "    print(f\"KNN Score: {score}\")\n",
    "    return knn\n",
    "\n",
    "def knn_pca_model(df, df_new, y_column):\n",
    "    train_data = df[df.columns.difference([y_column])]\n",
    "    test_data = df_new[df_new.columns.difference([y_column])]\n",
    "    pca = PCA(n_components = 0.9).fit(train_data)\n",
    "    print(pca.transform(train_data).shape)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=N_NEIGHBORS, p=DISTANCE_MEASURE)\n",
    "    knn.fit(pca.transform(train_data), df[y_column])\n",
    "\n",
    "    print(pca.transform(test_data).shape)\n",
    "    score = knn.score(pca.transform(test_data), df_new[y_column])\n",
    "    print(f\"KNN+PCA Score: {score}\")\n",
    "    return knn, pca\n",
    "\n",
    "knn = knn_model(df_train_new, train_y_new, y_column='user_id')\n",
    "knn_pca, pca = knn_pca_model(df_train_new, train_y_new, y_column='user_id')\n",
    "knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "\n<div id=\"altair-viz-6c35e048ea3846489479e199e0c02074\"></div>\n<script type=\"text/javascript\">\n  (function(spec, embedOpt){\n    const outputDiv = document.getElementById(\"altair-viz-6c35e048ea3846489479e199e0c02074\");\n    const paths = {\n      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext\",\n      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n    };\n\n    function loadScript(lib) {\n      return new Promise(function(resolve, reject) {\n        var s = document.createElement('script');\n        s.src = paths[lib];\n        s.async = true;\n        s.onload = () => resolve(paths[lib]);\n        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n        document.getElementsByTagName(\"head\")[0].appendChild(s);\n      });\n    }\n\n    function showError(err) {\n      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n      throw err;\n    }\n\n    function displayChart(vegaEmbed) {\n      vegaEmbed(outputDiv, spec, embedOpt)\n        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n    }\n\n    if(typeof define === \"function\" && define.amd) {\n      requirejs.config({paths});\n      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n    } else if (typeof vegaEmbed === \"function\") {\n      displayChart(vegaEmbed);\n    } else {\n      loadScript(\"vega\")\n        .then(() => loadScript(\"vega-lite\"))\n        .then(() => loadScript(\"vega-embed\"))\n        .catch(showError)\n        .then(() => displayChart(vegaEmbed));\n    }\n  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300, \"height\": 300, \"width\": 650}, \"axis\": {\"grid\": false, \"gridDash\": [1, 0, 1], \"gridWidth\": 0.5, \"labelColor\": \"#3A3F4A\", \"labelFont\": \"Ubuntu Mono\", \"labelFontSize\": 11, \"labelPadding\": 10, \"ticks\": false, \"titleColor\": \"#3A3F4A\", \"titleFont\": \"Ubuntu Mono\", \"titlePadding\": 10}, \"mark\": {}}, \"layer\": [{\"layer\": [{\"mark\": {\"type\": \"bar\", \"color\": \"#9400D3\", \"size\": 2}, \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"Accuracy\", \"scale\": {\"zero\": false}}, \"y\": {\"type\": \"nominal\", \"field\": \"Label\", \"scale\": {\"zero\": true}, \"sort\": [\"Keystokes Mean + STD\", \"Keystrokes Mean + Variance\", \"Keystrokes Mean\", \"... + Remove Outliers (baseline)\", \"... + Distinguish [Shift]\", \"... + Use Transition 2\", \"Keystrokes Median\", \"... + Manhattan Distance\", \"... + PCA\"], \"title\": null}}}, {\"mark\": {\"type\": \"circle\", \"color\": \"#9400D3\", \"size\": 50}, \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"Accuracy\"}, \"y\": {\"type\": \"nominal\", \"field\": \"Label\", \"scale\": {\"zero\": true}, \"sort\": [\"Keystokes Mean + STD\", \"Keystrokes Mean + Variance\", \"Keystrokes Mean\", \"... + Remove Outliers (baseline)\", \"... + Distinguish [Shift]\", \"... + Use Transition 2\", \"Keystrokes Median\", \"... + Manhattan Distance\", \"... + PCA\"]}}}, {\"data\": {\"url\": \"tmp/altdata/altair-data-0ccff6763571445c0d429026625d9698.json\", \"format\": {\"type\": \"json\"}}, \"mark\": {\"type\": \"bar\", \"color\": \"#00FF00\", \"size\": 2}, \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"Accuracy\", \"scale\": {\"zero\": false}}, \"y\": {\"type\": \"nominal\", \"field\": \"Label\", \"scale\": {\"zero\": true}, \"sort\": [\"Keystokes Mean + STD\", \"Keystrokes Mean + Variance\", \"Keystrokes Mean\", \"... + Remove Outliers (baseline)\", \"... + Distinguish [Shift]\", \"... + Use Transition 2\", \"Keystrokes Median\", \"... + Manhattan Distance\", \"... + PCA\"]}}}, {\"data\": {\"url\": \"tmp/altdata/altair-data-0ccff6763571445c0d429026625d9698.json\", \"format\": {\"type\": \"json\"}}, \"mark\": {\"type\": \"circle\", \"color\": \"#00FF00\", \"size\": 50}, \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"Accuracy\", \"scale\": {\"zero\": false}}, \"y\": {\"type\": \"nominal\", \"field\": \"Label\", \"scale\": {\"zero\": true}, \"sort\": [\"Keystokes Mean + STD\", \"Keystrokes Mean + Variance\", \"Keystrokes Mean\", \"... + Remove Outliers (baseline)\", \"... + Distinguish [Shift]\", \"... + Use Transition 2\", \"Keystrokes Median\", \"... + Manhattan Distance\", \"... + PCA\"]}}}]}], \"data\": {\"url\": \"tmp/altdata/altair-data-c2905520462346d8141e870e98f2d30e.json\", \"format\": {\"type\": \"json\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.0.2.json\"}, {\"mode\": \"vega-lite\"});\n</script>",
      "text/plain": "alt.LayerChart(...)"
     },
     "metadata": {},
     "execution_count": 285
    }
   ],
   "source": [
    "dd = pd.DataFrame(\n",
    "    (\n",
    "        (4, 'Keystokes Mean + STD', 0.5096153846153846),\n",
    "        (5, 'Keystrokes Mean + Variance', 0.5528846153846154),\n",
    "        (0, 'Keystrokes Mean', 0.5721153846153846),\n",
    "        (1, '... + Remove Outliers (baseline)', 0.703125),\n",
    "        (2, '... + Distinguish [Shift]', 0.7127403846153846),\n",
    "        (3, '... + Use Transition 2', 0.7271634615384616),\n",
    "        (7, 'Keystrokes Median', 0.7548076923076923), \n",
    "        (8, '... + Manhattan Distance', 0.8858173076923077),\n",
    "        (8, '... + PCA', 0.6716981132075471)\n",
    "    ),\n",
    "    columns=['Id', 'Label', 'Accuracy']\n",
    ")\n",
    "alt.layer(\n",
    "alt.Chart(dd).mark_bar(size=2, color='#9400D3').encode(\n",
    "    x=alt.X('Accuracy', scale=alt.Scale(zero=False)), \n",
    "    y=alt.Y('Label', scale=alt.Scale(zero=True), title=None, sort = list(dd['Label'].values))\n",
    "    )+ \\\n",
    "alt.Chart(dd).mark_circle(size=50, color='#9400D3').encode(\n",
    "        x='Accuracy', \n",
    "        y=alt.Y('Label', scale=alt.Scale(zero=True), sort = list(dd['Label'].values))\n",
    ") + \\\n",
    "alt.Chart(dd.loc[dd['Label']=='... + Remove Outliers (baseline)']).mark_bar(size=2, color='#00FF00').encode(\n",
    "    x=alt.X('Accuracy', scale=alt.Scale(zero=False)), \n",
    "    y=alt.Y('Label', scale=alt.Scale(zero=True), sort = list(dd['Label'].values))\n",
    "    ) + \\\n",
    "alt.Chart(dd.loc[dd['Label']=='... + Remove Outliers (baseline)']).mark_circle(size=50, color='#00FF00').encode(\n",
    "    x=alt.X('Accuracy', scale=alt.Scale(zero=False)), \n",
    "    y=alt.Y('Label', scale=alt.Scale(zero=True), sort = list(dd['Label'].values))\n",
    "    )\n",
    ").configure_mark(\n",
    "        # color=alt.Color('red')\n",
    "    ).configure_view(\n",
    "     width = 650,\n",
    "     height = 300).configure_axis(\n",
    "    # domain = False, \n",
    "    grid=False,\n",
    "    ticks = False,\n",
    "    labelPadding = 10,\n",
    "    labelFont = 'Ubuntu Mono',\n",
    "    labelFontSize = 11,\n",
    "    labelColor = '#3A3F4A',\n",
    "    titleFont = 'Ubuntu Mono',\n",
    "    titleColor = '#3A3F4A',\n",
    "    # titleAnchor = \"end\",\n",
    "    titlePadding = 10,\n",
    "    gridWidth = 0.5,\n",
    "    gridDash = [1, 0, 1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "\n<div id=\"altair-viz-413aae5cd87741f4946eae678229ec30\"></div>\n<script type=\"text/javascript\">\n  (function(spec, embedOpt){\n    const outputDiv = document.getElementById(\"altair-viz-413aae5cd87741f4946eae678229ec30\");\n    const paths = {\n      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext\",\n      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n    };\n\n    function loadScript(lib) {\n      return new Promise(function(resolve, reject) {\n        var s = document.createElement('script');\n        s.src = paths[lib];\n        s.async = true;\n        s.onload = () => resolve(paths[lib]);\n        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n        document.getElementsByTagName(\"head\")[0].appendChild(s);\n      });\n    }\n\n    function showError(err) {\n      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n      throw err;\n    }\n\n    function displayChart(vegaEmbed) {\n      vegaEmbed(outputDiv, spec, embedOpt)\n        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n    }\n\n    if(typeof define === \"function\" && define.amd) {\n      requirejs.config({paths});\n      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n    } else if (typeof vegaEmbed === \"function\") {\n      displayChart(vegaEmbed);\n    } else {\n      loadScript(\"vega\")\n        .then(() => loadScript(\"vega-lite\"))\n        .then(() => loadScript(\"vega-embed\"))\n        .catch(showError)\n        .then(() => displayChart(vegaEmbed));\n    }\n  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300, \"width\": 750}, \"axis\": {\"grid\": false, \"gridDash\": [1, 0, 1], \"gridWidth\": 0.5, \"labelColor\": \"#3A3F4A\", \"labelFont\": \"Ubuntu Mono\", \"labelFontSize\": 11, \"labelPadding\": 10, \"ticks\": false, \"titleColor\": \"#3A3F4A\", \"titleFont\": \"Ubuntu Mono\", \"titlePadding\": 10}}, \"layer\": [{\"layer\": [{\"mark\": {\"type\": \"bar\", \"color\": \"#9400D3\", \"size\": 2}, \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"Number of Features\", \"scale\": {\"bins\": [10, 20, 30, 40, 50, 60, 70, 80, 90]}}, \"y\": {\"type\": \"quantitative\", \"field\": \"Accuracy\", \"scale\": {\"zero\": true}}}}, {\"mark\": {\"type\": \"circle\", \"color\": \"#9400D3\", \"size\": 50}, \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"Number of Features\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"Accuracy\"}}}]}], \"data\": {\"url\": \"tmp/altdata/altair-data-146af0ca9239f7bc58cca97206ea7e84.json\", \"format\": {\"type\": \"json\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.0.2.json\"}, {\"mode\": \"vega-lite\"});\n</script>",
      "text/plain": "alt.LayerChart(...)"
     },
     "metadata": {},
     "execution_count": 206
    }
   ],
   "source": [
    "dd = pd.DataFrame(\n",
    "    (\n",
    "        (10, 0.62019),\n",
    "        (20, 0.664663),\n",
    "        (30, 0.67668269),\n",
    "        (40, 0.703125),\n",
    "        (50, 0.6899038461538461),\n",
    "        (60, 0.64663),\n",
    "        (70, 0.6045),\n",
    "        (80, 0.5528846153846154),\n",
    "        (90, 0.5060096153846154)\n",
    "    ),\n",
    "    columns=['Number of Features', 'Accuracy']\n",
    ")\n",
    "alt.layer(alt.Chart(dd).mark_bar(size=2, color='#9400D3').encode(\n",
    "    x=alt.X('Number of Features', scale=alt.Scale(bins=[10, 20, 30, 40, 50, 60, 70, 80, 90])), \n",
    "    y=alt.Y('Accuracy', scale=alt.Scale(zero=True)))+ \\\n",
    "alt.Chart(dd).mark_circle(size=50, color='#9400D3').encode(x='Number of Features', y='Accuracy')).configure_view(\n",
    "     width = 750).configure_axis(\n",
    "    # domain = False, \n",
    "    grid=False,\n",
    "    ticks = False,\n",
    "    labelPadding = 10,\n",
    "    labelFont = 'Ubuntu Mono',\n",
    "    labelFontSize = 11,\n",
    "    labelColor = '#3A3F4A',\n",
    "    titleFont = 'Ubuntu Mono',\n",
    "    titleColor = '#3A3F4A',\n",
    "    # titleAnchor = \"end\",\n",
    "    titlePadding = 10,\n",
    "    gridWidth = 0.5,\n",
    "    gridDash = [1, 0, 1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "34                            A187X82UVX9973\n60                            A1FSSSGYX9OZS2\n93                            A1OEHMFL5A0G29\n139                           A1YX045UYGCNLA\n176                           A28M2RVUTQO891\n206                           A2EQOFJNKS7RCN\n225                           A2JRENREH72502\n254                           A2S16E0HN8A3N7\n259                           A2T5T842FSABA3\n268                           A2W1E7UEQ7ZUQE\n289                           A32SJS0TTSRIM5\n298                           A34V3N0B4C3BMF\n299                           A35DSHKI68VP6V\n333                           A3D5C3AR576B1T\n342                           A3GMI3KMQ4QOFQ\n417                            ABVBWRI4D5O36\n418                            ABW7WZONWDBVZ\n427                            ADT8XTB3NGLTF\n428                            ADW0Y55EQN5SP\n434                            AFAWE4JWR9G84\n452                            AL34WN7X302EF\n457                            AMAOA3GTMDS94\n488                            AWYT0RI8P4YK0\n499                            acxngm3s98ttf\n511                           A1Q2Y8OZT0TJ2S\n526                           A2NTMYU9WLUDEO\n579                           A1MUO375X8D1Z7\n585                           A20IF612YY351J\n675                           A1ZRRIG16HVICC\n688                           A2EML740M3OWA9\n694                           A2KFFE8V9FUKN3\n702                           A2TX35M68DZHV2\n706                           A313ENOVCEU2VY\n711                           A3CXYVPO1IFDZI\n739                            APC3O2O8O9XPO\n748                         ?A1OLRUT93TXWEP?\n874                           A28WCYNS229OHH\n899                           A3RT2GUAQSV1DU\n1044                          A3FEDAI7F5MY3T\n1049                           A4WSGXF5IARBH\n1061    97fc22cf-aa61-4dcf-91a8-97d8fbf4a983\n1068    efd01132-1526-496b-a3ed-c55e50e785dd\nName: user_id, dtype: object"
     },
     "metadata": {},
     "execution_count": 312
    }
   ],
   "source": [
    "res = knn.predict(train_y_new[train_y_new.columns.difference(['user_id'])])\n",
    "_rev = train_y_new.copy() \n",
    "_rev['predicted_user_id'] = res\n",
    "# pd.set_option('display.max_rows', 100)\n",
    "_rev[_rev.user_id != _rev.predicted_user_id]['user_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "52"
     },
     "metadata": {},
     "execution_count": 295
    }
   ],
   "source": [
    "len(_rev[_rev.user_id != _rev.predicted_user_id]['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1071"
     },
     "metadata": {},
     "execution_count": 296
    }
   ],
   "source": [
    "len(train_y_new.user_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f5e52c3d7aff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFEATURES_COUNTER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'key'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'counter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.sort(reverse=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# pd.set_option('display.max_rows', 200)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# _a.sort_values(by=['counter'], ascending=False).head(200)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "_a=pd.DataFrame(list(FEATURES_COUNTER.items()), columns=['key', 'counter'])#.sort(reverse=True)\n",
    "# pd.set_option('display.max_rows', 200)\n",
    "# _a.sort_values(by=['counter'], ascending=False).head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'dict_items' object has no attribute '__reversed__'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-02d26e713156>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFEATURES_COUNTER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__reversed__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict_items' object has no attribute '__reversed__'"
     ]
    }
   ],
   "source": [
    "sorted(list(FEATURES_COUNTER.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "\n<div id=\"altair-viz-9169b8924a7c437f893742d1e7f5fdbb\"></div>\n<script type=\"text/javascript\">\n  (function(spec, embedOpt){\n    const outputDiv = document.getElementById(\"altair-viz-9169b8924a7c437f893742d1e7f5fdbb\");\n    const paths = {\n      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext\",\n      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n    };\n\n    function loadScript(lib) {\n      return new Promise(function(resolve, reject) {\n        var s = document.createElement('script');\n        s.src = paths[lib];\n        s.async = true;\n        s.onload = () => resolve(paths[lib]);\n        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n        document.getElementsByTagName(\"head\")[0].appendChild(s);\n      });\n    }\n\n    function showError(err) {\n      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n      throw err;\n    }\n\n    function displayChart(vegaEmbed) {\n      vegaEmbed(outputDiv, spec, embedOpt)\n        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n    }\n\n    if(typeof define === \"function\" && define.amd) {\n      requirejs.config({paths});\n      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n    } else if (typeof vegaEmbed === \"function\") {\n      displayChart(vegaEmbed);\n    } else {\n      loadScript(\"vega\")\n        .then(() => loadScript(\"vega-lite\"))\n        .then(() => loadScript(\"vega-embed\"))\n        .catch(showError)\n        .then(() => displayChart(vegaEmbed));\n    }\n  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"url\": \"tmp/altdata/altair-data-8f31a7b89e7cbc6279e61580590041b8.json\", \"format\": {\"type\": \"json\"}}, \"mark\": \"bar\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"counter\"}, \"y\": {\"type\": \"ordinal\", \"field\": \"key\", \"sort\": {\"field\": \"counter\", \"order\": \"descending\"}}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.0.2.json\"}, {\"mode\": \"vega-lite\"});\n</script>",
      "text/plain": "alt.Chart(...)"
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "alt.Chart(_a.sort_values(by=['counter'], ascending=False).head(20)).mark_bar().encode(\n",
    " x = 'counter:Q',\n",
    " y = alt.Y('key:O', sort = alt.Sort(field = 'counter', order='descending')),\n",
    ")#.transform_filter('datum.counter > 2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['space', 'E', 'T', 'A', 'O', 'backspace', 'N', 'I', 'S', 'R', 'H',\n       'backspace_backspace', 'L', 'E_space', 'D', 'space_T', 'U', 'C',\n       'space_A', 'T_H', 'S_space', 'M', 'shift', 'G', 'Y', 'T_space',\n       'F', 'H_E', 'W', 'P', 'D_space', 'A_N', 'I_N', 'R_E', 'N_space',\n       'Y_space', 'E_R', 'B', 'space_shift', 'space_I', 'space_O',\n       'space_W', 'V', 'dot', 'space_S', 'O_space', 'O_N', 'N_D', 'E_N',\n       'R_space', 'dot_space', 'A_T', 'O_U', 'T_O', 'space_C', 'I_T',\n       'space_B', 'A_R', 'E_S', 'H_A', 'I_S', 'V_E', 'comma', 'A_L',\n       'space_M', 'space_F', 'comma_space', 'R_I', 'O_R',\n       'space_backspace', 'L_E', 'S_T', 'N_T', 'N_G', 'space_P',\n       'space_H', 'S_E', 'T_I', 'A_space', 'M_E', 'space_G', 'T_E', 'E_D',\n       'F_space', 'L_space', 'E_A', 'K', 'A_S', 'B_E', 'M_A', 'L_L',\n       'G_space', '[shift]space', '[shift]I', 'space_R', 'space_D', 'U_N',\n       'O_F', 'H_O', 'H_I', 'C_O', 'shift_I', 'N_E', 'space_L', 'R_O',\n       'space_N', 'O_M', 'O_T', 'L_I', 'space_E', 'D_E', '[shift]T',\n       'N_S', 'I_C', 'C_E', 'L_Y', 'T_A', 'G_E', 'I_O', 'U_R', 'E_L',\n       'F_O', 'U_S', 'N_O', 'P_E', 'H_space', 'S_O', 'I_L', 'W_E',\n       'shift_T', 'C_H', 'C_A', 'P_L', 'U_L', 'E_T', 'W_A', 'A_Y', 'T_R',\n       'L_D', 'U_T', 'L_A', 'R_A', 'E_C', 'E_E', 'I_E', 'W_I',\n       '[shift]space_shift', 'backspace_space', 'G_U', 'W_H', 'S_H',\n       'A_V', 'A_C', 'E_backspace', 'O_O', 'space_space', 'O_P', 'R_Y',\n       'O_W', 'I_A', 'R_R', 'Þ', 'L_O', 'S_I', 'O_L', 'A_G', 'D_I', 'I_G',\n       'E_V', 'A_M', 'G_H', 'W_O', 'Y_O', 'M_O', 'backspace_shift', 'O_S',\n       'G_A', 'P_O', 'K_E', 'R_S', 'backspace_E', 'P_R', 'S_dot', 'E_dot',\n       'I_M', 'I_R', 'M_space', 'S_A', 'backspace_T', 'backspace_A', 'X',\n       'C_I', 'space_Y', 'E_Y', 'F_E', 'O_D', 'D_O', 'space_U', 'T_S',\n       'A_D'], dtype=object)"
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "_a.sort_values(by=['counter'], ascending=False).head(200).key.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-308-4ac4dfeedcd5>, line 1)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-308-4ac4dfeedcd5>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    se_sions['UserName'].unique())\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "se_sions['UserName'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "16"
     },
     "metadata": {},
     "execution_count": 309
    }
   ],
   "source": [
    "len(df_sessions['UserName'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}