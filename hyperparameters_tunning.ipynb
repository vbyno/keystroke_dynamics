{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tabulate\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DataTransformerRegistry.enable('default')"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "alt.data_transformers.enable('default', max_rows=None) \n",
    "# alt.renderers.enable('default')\n",
    "# alt.renderers.enable('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DataTransformerRegistry.enable('custom')"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Save temp altair json files in separate folder\n",
    "os.makedirs('tmp/altdata', exist_ok=True)\n",
    "\n",
    "def custom(data):\n",
    "    return alt.pipe(data, alt.to_json(filename='tmp/altdata/{prefix}-{hash}.{extension}') )\n",
    "\n",
    "alt.data_transformers.register('custom', custom)\n",
    "alt.data_transformers.enable('custom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_datasets(datasets):\n",
    "    return pd.concat(\n",
    "        (dataset[[\n",
    "            'UserName', \n",
    "            'AccessKey', \n",
    "            'Topic', \n",
    "            'Task',\n",
    "            'ReviewText', \n",
    "            'ReviewMeta'\n",
    "        ]] for dataset in datasets),\n",
    "        ignore_index=True)\n",
    "\n",
    "def read_dataset(files = ('data/ReviewAMT_500_t.csv', 'data/GayMarriage_400.csv', 'data/GunControl_400.csv')):\n",
    "    df_atm = pd.read_csv(files[0], sep='\\t')\n",
    "    df_gay = pd.read_csv(files[1], sep='\\t')\n",
    "    df_gun = pd.read_csv(files[2], sep='\\t')\n",
    "\n",
    "    df_atm.rename(columns = {'ReviewTopic': 'Topic'}, inplace=True)\n",
    "    df_atm['Task'] = df_atm['Task'].map(\n",
    "        {\n",
    "            \"Fake Review\": 'fake', \n",
    "            \"True Review\": 'true',\n",
    "            'Copy_1': 'copy_1',\n",
    "            'Copy_2': 'copy_2'\n",
    "        })\n",
    "    df_gay['Task'] = df_gay['Task'].map(\n",
    "        {\n",
    "            \"Fake Essay\": 'fake', \n",
    "            \"True Essay\": 'true',\n",
    "            'Copy_1': 'copy_1',\n",
    "            'Copy_2': 'copy_2'\n",
    "        }) \n",
    "    df_gun['Task'] = df_gun['Task'].map(\n",
    "        {\n",
    "            \"Fake Essay\": 'fake', \n",
    "            \"True Essay\": 'true',\n",
    "            'Copy_1': 'copy_1',\n",
    "            'Copy_2': 'copy_2'\n",
    "        }) \n",
    "    return concat_datasets((df_atm, df_gay, df_gun))\n",
    "\n",
    "df = read_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5200 entries, 0 to 5199\nData columns (total 6 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   UserName    5200 non-null   object\n 1   AccessKey   5200 non-null   object\n 2   Topic       5200 non-null   object\n 3   Task        5200 non-null   object\n 4   ReviewText  5200 non-null   object\n 5   ReviewMeta  5200 non-null   object\ndtypes: object(6)\nmemory usage: 243.9+ KB\n"
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                UserName                         AccessKey Topic    Task  \\\n0  A002160837SWJFPIAI7L7  392aa3e372054948a5cabd637b2e239b   AMT  copy_1   \n1  A002160837SWJFPIAI7L7  392aa3e372054948a5cabd637b2e239b   AMT  copy_2   \n2  A002160837SWJFPIAI7L7  392aa3e372054948a5cabd637b2e239b   AMT    fake   \n\n                                          ReviewText  \\\n0  Famous Daves is a good place to go for some go...   \n1  The Original Shrimp Place is a good place to c...   \n2  The Original Shrimp Place is a good place to c...   \n\n                                          ReviewMeta  \n0  0 MouseUp 0 0;535 KeyDown 16;776 KeyDown 70;79...  \n1  0 MouseUp 0 0;491 KeyDown 16;778 KeyDown 84;82...  \n2  0 MouseUp 0 0;849 KeyDown 16;966 KeyDown 84;10...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserName</th>\n      <th>AccessKey</th>\n      <th>Topic</th>\n      <th>Task</th>\n      <th>ReviewText</th>\n      <th>ReviewMeta</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A002160837SWJFPIAI7L7</td>\n      <td>392aa3e372054948a5cabd637b2e239b</td>\n      <td>AMT</td>\n      <td>copy_1</td>\n      <td>Famous Daves is a good place to go for some go...</td>\n      <td>0 MouseUp 0 0;535 KeyDown 16;776 KeyDown 70;79...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A002160837SWJFPIAI7L7</td>\n      <td>392aa3e372054948a5cabd637b2e239b</td>\n      <td>AMT</td>\n      <td>copy_2</td>\n      <td>The Original Shrimp Place is a good place to c...</td>\n      <td>0 MouseUp 0 0;491 KeyDown 16;778 KeyDown 84;82...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A002160837SWJFPIAI7L7</td>\n      <td>392aa3e372054948a5cabd637b2e239b</td>\n      <td>AMT</td>\n      <td>fake</td>\n      <td>The Original Shrimp Place is a good place to c...</td>\n      <td>0 MouseUp 0 0;849 KeyDown 16;966 KeyDown 84;10...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                          ReviewText  \\\n0  Linear algebra is central to almost all areas ...   \n1  Linear algebra is central to almost all areas ...   \n2  Linear algebra is central to almost all areas ...   \n\n                                          ReviewMeta  \\\n0  1582990688239 KeyDown 16;1582990688600 KeyDown...   \n1  1582996141506 KeyDown 16;1582996141595 KeyDown...   \n2  1582996489340 KeyDown 16;1582996489541 KeyDown...   \n\n                              AccessKey                              UserName  \\\n0  9d891be4-e43e-49f9-88bb-25314e670850  9d891be4-e43e-49f9-88bb-25314e670850   \n1  9d891be4-e43e-49f9-88bb-25314e670850  9d891be4-e43e-49f9-88bb-25314e670850   \n2  97fc22cf-aa61-4dcf-91a8-97d8fbf4a983  97fc22cf-aa61-4dcf-91a8-97d8fbf4a983   \n\n     Task Topic  \n0  copy_1    LA  \n1  copy_2    LA  \n2  copy_1    LA  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ReviewText</th>\n      <th>ReviewMeta</th>\n      <th>AccessKey</th>\n      <th>UserName</th>\n      <th>Task</th>\n      <th>Topic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Linear algebra is central to almost all areas ...</td>\n      <td>1582990688239 KeyDown 16;1582990688600 KeyDown...</td>\n      <td>9d891be4-e43e-49f9-88bb-25314e670850</td>\n      <td>9d891be4-e43e-49f9-88bb-25314e670850</td>\n      <td>copy_1</td>\n      <td>LA</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Linear algebra is central to almost all areas ...</td>\n      <td>1582996141506 KeyDown 16;1582996141595 KeyDown...</td>\n      <td>9d891be4-e43e-49f9-88bb-25314e670850</td>\n      <td>9d891be4-e43e-49f9-88bb-25314e670850</td>\n      <td>copy_2</td>\n      <td>LA</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Linear algebra is central to almost all areas ...</td>\n      <td>1582996489340 KeyDown 16;1582996489541 KeyDown...</td>\n      <td>97fc22cf-aa61-4dcf-91a8-97d8fbf4a983</td>\n      <td>97fc22cf-aa61-4dcf-91a8-97d8fbf4a983</td>\n      <td>copy_1</td>\n      <td>LA</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "def read_group_sessions(name='data/keystroke_sessions-2020-03-20.csv'):\n",
    "    _a = pd.read_csv(name)\n",
    "    # _a.rename(columns={\"AccessKey\": \"UserName\", }\n",
    "    _a['UserName'] = _a['AccessKey']\n",
    "    _a.drop(columns=['attempt_id', 'ReviewDate'], inplace=True)\n",
    "    _a['Task'] = ''\n",
    "    _a['Topic'] = 'LA'\n",
    "    attempts = {}\n",
    "    for i, row in _a.iterrows():\n",
    "        key = row['UserName']\n",
    "        if key not in attempts: attempts[key] = 0\n",
    "        attempts[key] += 1\n",
    "        _a.loc[i, 'Task'] = f\"copy_{attempts[key]}\"\n",
    "\n",
    "    return _a\n",
    "\n",
    "def add_text_length_column(df):\n",
    "    df['TextLenght'] = df.apply(lambda x: len(x['ReviewText'].split()), axis = 1)\n",
    "\n",
    "df_sessions = read_group_sessions()\n",
    "df_sessions.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5231 entries, 0 to 5230\nData columns (total 7 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   UserName    5231 non-null   object\n 1   AccessKey   5231 non-null   object\n 2   Topic       5231 non-null   object\n 3   Task        5231 non-null   object\n 4   ReviewText  5231 non-null   object\n 5   ReviewMeta  5231 non-null   object\n 6   TextLenght  5231 non-null   int64 \ndtypes: int64(1), object(6)\nmemory usage: 286.2+ KB\n"
    }
   ],
   "source": [
    "# df = concat_datasets((df, df_sessions))\n",
    "# add_text_length_column(df)\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_keystroke(line):\n",
    "    res = line.split(' ')\n",
    "    if len(res) > 3:\n",
    "        return f'UNKNOWN: {line}'\n",
    "    \n",
    "    time, command, key = res\n",
    "    return (time, command, key, chr(int(key)))\n",
    "\n",
    "def code_to_str(keycode):\n",
    "    keycode = int(keycode)\n",
    "    mappings = {\n",
    "        16: 'shift',\n",
    "        8: 'backspace',\n",
    "        32: 'space',\n",
    "        188: 'comma',\n",
    "        190: 'dot'\n",
    "    }\n",
    "    return mappings.get(keycode, chr(keycode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque \n",
    "\n",
    "def process_keystrokes(inputs, humanize=False, distinguish_shift=True):      \n",
    "    MOUSE_UP = 'MouseUp'\n",
    "    KEY_DOWN = 'KeyDown'\n",
    "    KEY_UP = 'KeyUp'\n",
    "    TRANSITION_2 = 'transition_2'\n",
    "    dwells = {}\n",
    "    transitions_1 = {}\n",
    "    transitions_2 = {}\n",
    "    key_downs = {}\n",
    "    keys_queue = deque([])\n",
    "    last_key_up = None\n",
    "    \n",
    "    def record_key(code1, code2, value, collection):\n",
    "        key = \"\"\n",
    "        if collection is transitions_2:\n",
    "            key = key + \"-\"\n",
    "        if (16 in key_downs or last_key_up == 16) and code1 != 16 and distinguish_shift:\n",
    "            key = key + \"[shift]\"\n",
    "        if code2:\n",
    "            key = key + f\"{code1}_{code2}\"\n",
    "        else:\n",
    "            key = key + f\"{code1}\"\n",
    "\n",
    "        if key not in collection: \n",
    "            collection[key] = []\n",
    "        collection[key].append(value)\n",
    "\n",
    "    for keystroke in inputs.split(';'):\n",
    "        res = keystroke.split(' ')\n",
    "        \n",
    "        if len(res) < 3: continue  \n",
    "        if res[1] == 'MouseUp': continue\n",
    "\n",
    "        time, command, code = res\n",
    "        time = int(time)\n",
    "        code = int(code)\n",
    "        \n",
    "        if command == KEY_DOWN:\n",
    "            if keys_queue:\n",
    "                prev_code, prev_time_down, prev_time_up = keys_queue[0]\n",
    "\n",
    "                if prev_time_up: \n",
    "                    record_key(prev_code, code, time - prev_time_up, transitions_2)\n",
    "\n",
    "                record_key(prev_code, code, time - prev_time_down, transitions_1)\n",
    "            \n",
    "            key_downs[code] = time\n",
    "            keys_queue.appendleft([code, time, None])\n",
    "            \n",
    "        if command == KEY_UP:\n",
    "            following_key = None\n",
    "            for i_key in keys_queue:\n",
    "                if i_key[0] == code:\n",
    "                    i_key[2] = time\n",
    "                    record_key(code, None, time - i_key[1], dwells)\n",
    "                    \n",
    "                    if following_key and following_key[1] < i_key[2]:\n",
    "                        record_key(i_key[0], following_key[0], following_key[1] - i_key[2], transitions_2)\n",
    "                    break\n",
    "\n",
    "                following_key = i_key\n",
    "\n",
    "            if code in key_downs: del(key_downs[code])\n",
    "            last_key_up = code\n",
    "\n",
    "    if humanize:\n",
    "        new_dwells = {}\n",
    "        new_transitions_1 = {}\n",
    "        new_transitions_2 = {}\n",
    "        shift_h = \"[shift]\"\n",
    "\n",
    "        for key, inputs in dwells.items():\n",
    "            prefix = \"\"\n",
    "            if shift_h in key:\n",
    "                key = key[7:]\n",
    "                prefix = shift_h\n",
    "            new_key = prefix + f\"{code_to_str(int(key))}\"\n",
    "            new_dwells[new_key] = sorted(inputs)\n",
    "\n",
    "        for key, inputs in transitions_1.items():\n",
    "            try:\n",
    "                k1, k2 = key.split(\"_\")\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            prefix = \"\"\n",
    "            if shift_h in k1:\n",
    "                k1 = k1[7:]\n",
    "                prefix = shift_h\n",
    "\n",
    "            key = f\"{prefix}{code_to_str(int(k1))}_{code_to_str(int(k2))}\"\n",
    "            new_transitions_1[key] = sorted(inputs)\n",
    "        for key, inputs in transitions_2.items(): \n",
    "            try:\n",
    "                k1, k2 = key.split(\"_\")\n",
    "            except:\n",
    "                continue\n",
    "            k1 = k1[1:] # here is a \"-\" sign\n",
    "\n",
    "            prefix = \"\"\n",
    "            if shift_h in k1:\n",
    "                k1 = k1[7:]\n",
    "                prefix = shift_h\n",
    "\n",
    "            key = f\"-{prefix}{code_to_str(int(k1))}_{code_to_str(int(k2))}\"\n",
    "            new_transitions_2[key] = inputs #sorted(inputs)\n",
    "\n",
    "        return new_dwells, new_transitions_1, new_transitions_2\n",
    "\n",
    "    return dwells, transitions_1, transitions_2\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'A': [127, 151],\n '[shift]H': [135],\n '[shift]E': [152],\n '[shift]L': [110, 127],\n 'shift': [2600, 3400],\n '[shift]O': [159]}"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "ss = \"1583128026026 KeyDown 65;1583128026177 KeyUp 65;1583128026810 KeyDown 65;1583128026937 KeyUp 65;1583128027529 KeyDown 16;1583128028034 KeyDown 72;1583128028169 KeyUp 72;1583128028801 KeyDown 69;1583128028953 KeyUp 69;1583128029298 KeyDown 76;1583128029408 KeyUp 76;1583128029586 KeyDown 76;1583128029713 KeyUp 76;1583128030929 KeyUp 16;1583128031681 KeyDown 16;1583128032402 KeyDown 79;1583128032561 KeyUp 79;1583128034281 KeyUp 16\"\n",
    "\n",
    "dwells, transitions_1, transitions_2 = process_keystrokes(ss, humanize=True)\n",
    "dwells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 3920 entries, 0 to 5229\nData columns (total 6 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   UserName    3920 non-null   object\n 1   AccessKey   3920 non-null   object\n 2   Topic       3920 non-null   object\n 3   Task        3920 non-null   object\n 4   ReviewText  3920 non-null   object\n 5   ReviewMeta  3920 non-null   object\ndtypes: object(6)\nmemory usage: 214.4+ KB\n"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# def split_datasets(df):\n",
    "#     df1 = df.loc[df['Task'] == 'copy_1']\n",
    "#     df1.drop_duplicates(subset =\"UserName\", keep = False, inplace = True) \n",
    "\n",
    "#     df2 = df.loc[df['Task'] == 'copy_2']\n",
    "#     df2.drop_duplicates(subset =\"UserName\", keep = False, inplace = True) \n",
    "\n",
    "#     train_X, val_X = train_test_split(df1, test_size=0.2, random_state=42)\n",
    "#     train_y = df2[df2['UserName'].isin(train_X['UserName'].tolist())]\n",
    "#     val_y = df2[df2['UserName'].isin(val_X['UserName'].tolist())]\n",
    "#     return train_X, val_X, train_y, val_y\n",
    "\n",
    "def split_datasets(df):\n",
    "    df_new = df.copy()\n",
    "    # df_new = df_new.drop_duplicates(subset =[\"UserName\", \"Task\"], keep = False, inplace = False) \n",
    "    # df1 = df_new.loc[df['Task'].isin(['copy_1', 'false', 'true', 'copy_3'])]\n",
    "    test_column = 'copy_2'\n",
    "    df1 = df_new.loc[df['Task'] != test_column]\n",
    "    df2 = df_new.loc[df['Task'] == test_column]\n",
    "    return df1, None, df2, None\n",
    "\n",
    "df_train, df_val, train_y, val_y = split_datasets(concat_datasets((df, df_sessions)))\n",
    "# df_train, df_val, train_y, val_y = split_datasets(df)\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(14.4, 8.2365041127896, 67.84)"
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "source": [
    "def timestamp_values(array, coef=1.5):\n",
    "    array = np.array(array)\n",
    "    q1 = np.quantile(array, 0.25)\n",
    "    q3 = np.quantile(array, 0.75)\n",
    "    iqr = q3 - q1\n",
    "    array = array[(array > (q1 - coef * iqr)) & (array < (q3 + coef * iqr))]\n",
    "    return array.mean(), array.std(), array.var()\n",
    "\n",
    "timestamp_values([1, 11, 23, 14, 23, 1111])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = ['T_H', 'H_E', 'A_N', 'T_space', 'R_E', 'I_N', 'E', 'A', 'R', 'I', 'O', 'T', 'N']\n",
    "FEATURES = [\n",
    "    'S_space', 'space_A', 'D_space', 'E_space', 'space_T', 'backspace_backspace', \n",
    "    'T_H', 'H_E', 'A_N', 'T_space', 'R_E', 'I_N', \n",
    "    'E', 'A', 'R', 'I', 'O', 'T', 'N', 'S', 'space'\n",
    "    ]\n",
    "\n",
    "FEATURES = ['backspace_backspace', \"E_space\", \"space_T\", \"T_H\", \"space_A\", \"S_space\", \"T_space\", \"H_E\", \"D_space\", \"A_N\", \"I_N\", \"R_E\", \"N_space\", \"E_R\", \"Y_space\", \"space_I\", \"space_O\", \"O_space\", \"space_W\", \"space_S\", \"O_N\", \"N_D\", \"E_N\", \"R_space\", \"O_U\", \"space\", \"E\", \"backspace\", \"T\", \"A\", \"O\", \"I\", \"N\", \"S\", \"R\"]#, \"H\", \"L\", \"D\", \"U\", \"C\", \"M\", \"G\", \"Y\", \"F\", \"W\", \"P\", \"B\", \"comma\", \"V\", \"dot\", \"K\"]\n",
    "\n",
    "USE_TRANSITION_2 = True\n",
    "N_NEIGHBORS=1\n",
    "\n",
    "def process_and_unite_keystrokes(\n",
    "    inputs, \n",
    "    humanize=True, \n",
    "    distinguish_shift=True,\n",
    "    normalizator = timestamp_values,\n",
    "    normalizator_coef = 1.5,\n",
    "    transition_2=False): \n",
    "    a,b,c = process_keystrokes(inputs, humanize, distinguish_shift)\n",
    "    raw_data = {**a , **b, **c}\n",
    "    res = {}\n",
    "\n",
    "    features = FEATURES\n",
    "    if transition_2:\n",
    "        features = list(map(lambda x: x if \"_\" not in x else f\"-{x}\", features))\n",
    "\n",
    "    for feature in features:\n",
    "        if feature in raw_data: \n",
    "            mean, std, var = normalizator(raw_data[feature], normalizator_coef)\n",
    "        else: \n",
    "            mean, std, var = None, None, None\n",
    "\n",
    "        res[f\"{feature}_mean\"] = mean \n",
    "        res[f\"{feature}_std\"] = std \n",
    "        # res[f\"{feature}_var\"] = var\n",
    "\n",
    "    return res\n",
    "\n",
    "def mutate_dataset(df, \n",
    "    user_id_column = \"UserName\", \n",
    "    keystrokes_column=\"ReviewMeta\", \n",
    "    transition_2=False):\n",
    "    res = []\n",
    "    for index, inputs in df.iterrows():\n",
    "        data = process_and_unite_keystrokes(inputs[keystrokes_column], transition_2=transition_2)\n",
    "        res.append({'user_id': inputs[user_id_column], **data})\n",
    "    return pd.DataFrame(res)\n",
    "\n",
    "def standartize_dataset(res):\n",
    "    modifiers = {}\n",
    "    for column in res.columns.difference(['user_id']):\n",
    "        mean_v = res[column].mean()\n",
    "\n",
    "        # Fill n/a values with mean\n",
    "        res[column].fillna(mean_v, inplace=True)\n",
    "\n",
    "        min_v = res[column].min()\n",
    "        max_v = res[column].max()\n",
    "        res[column] = res[column].apply(lambda x: (x - min_v)/(max_v - min_v))\n",
    "\n",
    "        # Save modifiers so that they could be applied to \n",
    "        modifiers[column] = { 'mean': mean_v, 'min': min_v, 'max': max_v }\n",
    "\n",
    "    return res, modifiers\n",
    "\n",
    "def standartize_by_modifiers(res, modifiers, features = FEATURES): \n",
    "    for column in res.columns.difference(['user_id']):\n",
    "        # Fill n/a values with mean\n",
    "        res[column].fillna(modifiers[column]['mean'], inplace=True)\n",
    "\n",
    "        min_v = modifiers[column]['min']\n",
    "        max_v = modifiers[column]['max']\n",
    "        res[column] = res[column].apply(lambda x: (x - min_v)/(max_v - min_v))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                 user_id  -backspace_backspace_mean  -backspace_backspace_std  \\\n0  A002160837SWJFPIAI7L7                   0.014901                  0.005940   \n1   A0436270XG2E3RS5T61O                   0.033394                  0.030202   \n2         A109TOWKB3DY3P                   0.015475                  0.002943   \n\n   -E_space_mean  -E_space_std  -space_T_mean  -space_T_std  -T_H_mean  \\\n0       0.091995      0.028029       0.082801      0.012082   0.248217   \n1       0.120144      0.055283       0.120019      0.020126   0.572880   \n2       0.088783      0.021113       0.071003      0.017613   0.527480   \n\n   -T_H_std  -space_A_mean  ...    B_mean     B_std  comma_mean  comma_std  \\\n0  0.217384       0.072532  ...  0.623260  0.197888    0.350000   0.182182   \n1  0.073518       0.069613  ...  0.268605  0.176101    0.711455   0.018961   \n2  0.091219       0.060966  ...  0.818414  0.050663    0.482000   0.086754   \n\n     V_mean     V_std  dot_mean   dot_std    K_mean     K_std  \n0  0.467476  0.121124  0.495890  0.027346  0.393548  0.172294  \n1  0.460538  0.016005  0.479628  0.191362  0.389560  0.057543  \n2  0.586188  0.393103  0.457205  0.137864  0.453959  0.040014  \n\n[3 rows x 103 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>-backspace_backspace_mean</th>\n      <th>-backspace_backspace_std</th>\n      <th>-E_space_mean</th>\n      <th>-E_space_std</th>\n      <th>-space_T_mean</th>\n      <th>-space_T_std</th>\n      <th>-T_H_mean</th>\n      <th>-T_H_std</th>\n      <th>-space_A_mean</th>\n      <th>...</th>\n      <th>B_mean</th>\n      <th>B_std</th>\n      <th>comma_mean</th>\n      <th>comma_std</th>\n      <th>V_mean</th>\n      <th>V_std</th>\n      <th>dot_mean</th>\n      <th>dot_std</th>\n      <th>K_mean</th>\n      <th>K_std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A002160837SWJFPIAI7L7</td>\n      <td>0.014901</td>\n      <td>0.005940</td>\n      <td>0.091995</td>\n      <td>0.028029</td>\n      <td>0.082801</td>\n      <td>0.012082</td>\n      <td>0.248217</td>\n      <td>0.217384</td>\n      <td>0.072532</td>\n      <td>...</td>\n      <td>0.623260</td>\n      <td>0.197888</td>\n      <td>0.350000</td>\n      <td>0.182182</td>\n      <td>0.467476</td>\n      <td>0.121124</td>\n      <td>0.495890</td>\n      <td>0.027346</td>\n      <td>0.393548</td>\n      <td>0.172294</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A0436270XG2E3RS5T61O</td>\n      <td>0.033394</td>\n      <td>0.030202</td>\n      <td>0.120144</td>\n      <td>0.055283</td>\n      <td>0.120019</td>\n      <td>0.020126</td>\n      <td>0.572880</td>\n      <td>0.073518</td>\n      <td>0.069613</td>\n      <td>...</td>\n      <td>0.268605</td>\n      <td>0.176101</td>\n      <td>0.711455</td>\n      <td>0.018961</td>\n      <td>0.460538</td>\n      <td>0.016005</td>\n      <td>0.479628</td>\n      <td>0.191362</td>\n      <td>0.389560</td>\n      <td>0.057543</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A109TOWKB3DY3P</td>\n      <td>0.015475</td>\n      <td>0.002943</td>\n      <td>0.088783</td>\n      <td>0.021113</td>\n      <td>0.071003</td>\n      <td>0.017613</td>\n      <td>0.527480</td>\n      <td>0.091219</td>\n      <td>0.060966</td>\n      <td>...</td>\n      <td>0.818414</td>\n      <td>0.050663</td>\n      <td>0.482000</td>\n      <td>0.086754</td>\n      <td>0.586188</td>\n      <td>0.393103</td>\n      <td>0.457205</td>\n      <td>0.137864</td>\n      <td>0.453959</td>\n      <td>0.040014</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 103 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "df_train_new, modifiers = standartize_dataset(mutate_dataset(df_train, transition_2=USE_TRANSITION_2))\n",
    "train_y_new = standartize_by_modifiers(mutate_dataset(train_y, transition_2=USE_TRANSITION_2), modifiers)\n",
    "train_y_new.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "KNN Score: 0.9145690312738368\n(3920, 40)\n(1311, 40)\nKNN+PCA Score: 0.6773455377574371\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n                     metric_params=None, n_jobs=None, n_neighbors=1, p=1,\n                     weights='uniform')"
     },
     "metadata": {},
     "execution_count": 142
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def knn_model(df, df_new, y_column): \n",
    "    knn = KNeighborsClassifier(n_neighbors=N_NEIGHBORS, p=1)\n",
    "    knn.fit(df[df.columns.difference([y_column])], df[y_column])\n",
    "    score = knn.score(df_new[df_new.columns.difference([y_column])], df_new[y_column])\n",
    "    print(f\"KNN Score: {score}\")\n",
    "    return knn\n",
    "\n",
    "def knn_pca_model(df, df_new, y_column):\n",
    "    train_data = df[df.columns.difference([y_column])]\n",
    "    test_data = df_new[df_new.columns.difference([y_column])]\n",
    "    pca = PCA(n_components = 0.9).fit(train_data)\n",
    "    print(pca.transform(train_data).shape)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=N_NEIGHBORS, p=1)\n",
    "    knn.fit(pca.transform(train_data), df[y_column])\n",
    "\n",
    "    print(pca.transform(test_data).shape)\n",
    "    score = knn.score(pca.transform(test_data), df_new[y_column])\n",
    "    print(f\"KNN+PCA Score: {score}\")\n",
    "    return knn, pca\n",
    "\n",
    "knn = knn_model(df_train_new, train_y_new, y_column='user_id')\n",
    "knn_pca, pca = knn_pca_model(df_train_new, train_y_new, y_column='user_id')\n",
    "knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = knn.predict(train_y_new[train_y_new.columns.difference(['user_id'])])\n",
    "# _rev = train_y_new.copy() \n",
    "# _rev['predicted_user_id'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "5                             A10T740JW5MQDA\n13                            A12E72AAMBWN9O\n39                            A19M5ECA9D9H80\n41                            A1AK0C9AYPTABN\n42                             A1B7O88JBR3NU\n44                            A1BDBKDS7F7OMW\n46                            A1BSALLPX6MSI4\n53                            A1CY5KVC753NQ9\n60                            A1FSSSGYX9OZS2\n89                            A1NM7ZPZ3NH412\n91                            A1NW8TTOYMEJEP\n92                            A1OB960PNAUAAS\n93                            A1OEHMFL5A0G29\n104                           A1SGSI91JYSV9Q\n115                           A1TU5JYP6K71GZ\n120                           A1UPWRVJKFV8EH\n126                           A1W6X3VNHHVIND\n130                           A1XD70FK0LGCYZ\n148                           A21EPR8KW0GWX2\n154                           A231ZXYHPSNUJQ\n159                           A246AT3K8XQZ0N\n167                           A261I77RAWTJM4\n176                           A28M2RVUTQO891\n206                           A2EQOFJNKS7RCN\n208                           A2F3ZR1HIX7WX3\n212                           A2GXD2V6YEL7OA\n217                           A2H9HL8YOPSMYR\n219                           A2I1X1A2N4G3TO\n220                           A2J7G90B7E39ME\n225                           A2JRENREH72502\n244                            A2OZGNW6THEMJ\n254                           A2S16E0HN8A3N7\n262                           A2ULGS0MNR975M\n272                           A2X1LQ0SWMZCDI\n291                           A33MLL0V5UMSCC\n298                           A34V3N0B4C3BMF\n299                           A35DSHKI68VP6V\n306                           A379ZZ5NWGWJKS\n320                           A3A4ELRGUYNNS8\n327                           A3BXKJG15LVQTV\n340                           A3FSI6EIB1M6YR\n348                            A3JVKK8BGIZ1K\n365                           A3QJ0OWM954E76\n367                           A3QS0S6B9P169W\n384                            A3VIYM4NN0SSL\n387                            A47NS9NARXRKS\n395                            A5LLSZG8YCAZF\n404                            A95RJNEL7V13M\n417                            ABVBWRI4D5O36\n442                            AHYJONIS0LE1X\n450                            AK0RQYEM2D0AY\n452                            AL34WN7X302EF\n458                            AMK0Y4BKU4EJE\n469                            AQW8DPB4P4XFN\n470                            ARVFVY7B3KGRY\n471                            ARYH49BS0B1RS\n481                            AV472ZALVT6WS\n484                            AVOF14300525D\n488                            AWYT0RI8P4YK0\n497                            AZTHBV93S8U3T\n499                            acxngm3s98ttf\n508                           A1FHLN84WI0N31\n512                           A1LTLK14NRF7VG\n516                           A1QHTMMXFNYJYU\n534                           A2FY1GL04ZI859\n558                           A3BXKJG15LVQTV\n560                           A3C2TSXWDYBZHA\n573                           A3QS0S6B9P169W\n598                            AZUFXOGS583TO\n624                           A20IF612YY351J\n635                           A2HR27LMSYOEH3\n639                           A2MSVKXC1F3WIU\n672                           A3PRQ2GSU42718\n733                           A2EML740M3OWA9\n759                           A3CXYVPO1IFDZI\n767                           A3KZZZE977EE65\n779                            A481HCC60DV7K\n800                         ?A1OLRUT93TXWEP?\n807                           A15S8DPIZ915JA\n814                           A1GFLU1X1ZIIRI\n847                           A30X2THN9JDWYF\n860                           A3KFXPAE40VKWY\n869                           A3TRTU5C4GDH6O\n881                            ADI3KIOE5MMNX\n921                           A1TNED9R7PWEKG\n935                           A27RHMZ009MD4M\n941                           A2KT91ZJC2ENH4\n950                           A2Z8SR1UU09HO5\n953                           A34P5NWNC6MZNO\n987                            ANW7R2VV3V630\n992                            ASLCXPPN9SV69\n993                            ASSVV3K7SV9JT\n1010                          A1JJ5AU2093QYE\n1025                          A21GQC29SYGVL1\n1058                          A31AG5Q0S5OI5V\n1071                          A3K7EUNGDPUFGW\n1073                          A3PDOZ6I8PE9ZK\n1095                           AU7V52XJGL5C4\n1107                          A1B4HMTVYKMJ2U\n1116                          A1FHLN84WI0N31\n1161                          A35DSHKI68VP6V\n1179                           ACFBUSLSNUGRU\n1211                          A1A5PM554V2L19\n1215                          A1GFLU1X1ZIIRI\n1218                          A1HJ8KQ2SO61YW\n1234                          A24NCF4KFZQHL0\n1240                          A2EML740M3OWA9\n1243                          A2PAO2ENJ5XY1T\n1260                          A3ES3R45N43ZSX\n1272                          A3S3D4TI6N8873\n1290                           APQ5FYQDBUVPZ\n1308    efd01132-1526-496b-a3ed-c55e50e785dd\nName: user_id, dtype: object"
     },
     "metadata": {},
     "execution_count": 145
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 200)\n",
    "_rev[_rev.user_id != _rev.predicted_user_id]['user_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1071"
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "source": [
    "len(train_y_new.user_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}